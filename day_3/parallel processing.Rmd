
---
title: Parallel processing
author: "Oleksii Yehorchenkov"
date: "30 11 2020"
output: html_document
---

This tutorial is based on https://github.com/lgreski/datasciencectacontent/blob/master/markdown/pml-randomForestPerformance.md

## The Process: A Parallel Implementation of Random Forest

Once a person works through the varied sources of documentation on the machine learning models and supporting R packages, the process for executing a random forest model (or any other model) in `caret::train()` is relatively straightforward, and includes the following steps.

1. Configure parallel processing
2. Configure trainControl object
3. Develop training model
4. De-register parallel processing cluster

### Prerequisite: Selecting a Machine Learning Problem

For the purpose of illustrating the syntax required for parallel processing, we'll use the `Sonar` data set that is also used as the example in the [caret model training documentation](http://topepo.github.io/caret/training.html).

```{r, results='hide', message=FALSE}
library(mlbench)
data(Sonar)
library(caret)
set.seed(95014)

```

### Step 1: Configure parallel processing

Parallel processing in `caret` can be accomplished with the `parallel` and `doParallel` packages.  The following code loads the required libraries (note, these libraries also depend on the `iterators` and `foreach` libraries).

```{r}
library(parallel)
library(doParallel)
cluster <- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cluster)
```

### Step 2: Configure trainControl object

The most critical arguments for the trainControl function are the resampling method `method`, the `number` that specifies the quantity of folds for k-fold cross-validation, and `allowParallel` which tells caret to use the cluster that we've registered in the previous step.

```{r}
fitControl <- trainControl(method = "cv", number = 5,
                           allowParallel = TRUE)
```

### Step 3: Develop training model

Next, we use `caret::train()` to train the model, using the `trainControl()` object that we just created.

```{r}
system.time(fit <- train(Class ~ ., method="rf",data=Sonar,
                         trControl = fitControl))
```
### Step 4: De-register parallel processing cluster

After processing the data, we explicitly shut down the cluster by calling the `stopCluster()` function.

```{r}
stopCluster(cluster)
registerDoSEQ()
```

At this point we have a trained model in the `fit` object, and can take a number of steps to evaluate the suitability of this model, including accuracy and a confusion matrix that is based on comparing the modeled data to the held out folds.

### Comparing with non-parallel processing

```{r}
fitControl <- trainControl(method = "cv", number = 5)
system.time(fit <- train(Class ~ ., method="rf",data=Sonar,
                         trControl = fitControl))
```
Results of benchmarks measured on the HP Omen laptop with Intel® Core™ i7-4720HQ processor:

1. Linear Discriminant Analysis
- Multi-threaded: 2.38  seconds
- Single-threaded: 2.41 seconds
2. Random Forest
- Multi-threaded: 193.2 seconds
- Single-threaded: 462.6 seconds




